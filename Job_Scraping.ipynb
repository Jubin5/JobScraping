{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries if not already installed\n",
        "!pip install schedule\n",
        "!pip install python-telegram-bot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYdsMv7gMDkC",
        "outputId": "01968588-d1cf-4276-c4b8-3fe7e656d57b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting schedule\n",
            "  Downloading schedule-1.2.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "Downloading schedule-1.2.2-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: schedule\n",
            "Successfully installed schedule-1.2.2\n",
            "Collecting python-telegram-bot\n",
            "  Downloading python_telegram_bot-22.1-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: httpx~=0.27 in /usr/local/lib/python3.11/dist-packages (from python-telegram-bot) (0.28.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx~=0.27->python-telegram-bot) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx~=0.27->python-telegram-bot) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx~=0.27->python-telegram-bot) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx~=0.27->python-telegram-bot) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx~=0.27->python-telegram-bot) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx~=0.27->python-telegram-bot) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx~=0.27->python-telegram-bot) (4.13.2)\n",
            "Downloading python_telegram_bot-22.1-py3-none-any.whl (702 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m702.3/702.3 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-telegram-bot\n",
            "Successfully installed python-telegram-bot-22.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "import joblib\n",
        "import time\n"
      ],
      "metadata": {
        "id": "GiOLexEjAo_J"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTwAyu46Ah25",
        "outputId": "6e78beb4-7f2c-4501-ddef-68a5bad5d208"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping page: 1\n",
            "Scraping page: 2\n",
            "                                               Title         Company  \\\n",
            "0          Machine Learning Physical Design Engineer          Google   \n",
            "1  Staff Software Engineer - Monetization, Poe (R...     Quora, Inc.   \n",
            "2  Staff Backend Engineer - Bot Creator Ecosystem...     Quora, Inc.   \n",
            "3  Senior Backend Engineer - Bot Creator Ecosyste...     Quora, Inc.   \n",
            "4                         Data Scientist Lead - AIML  JPMorgan Chase   \n",
            "\n",
            "                      Location Experience  \\\n",
            "0  Bengaluru, Karnataka, India   4-6 year   \n",
            "1                        India  8-10 year   \n",
            "2                        India  8-10 year   \n",
            "3                        India   6-8 year   \n",
            "4  Bengaluru, Karnataka, India   6-8 year   \n",
            "\n",
            "                                             Summary  \\\n",
            "0  Minimum qualifications:Bachelor's degree in El...   \n",
            "1  About Quora:Quora’s mission is to grow and sha...   \n",
            "2  About Quora:Quora’s mission is to grow and sha...   \n",
            "3  About Quora:Quora’s mission is to grow and sha...   \n",
            "4  We have an opportunity to impact your career a...   \n",
            "\n",
            "                                              Skills  \n",
            "0  Aartificial intelligence,Algorithms,Data struc...  \n",
            "1  Aartificial intelligence,Analytical and Proble...  \n",
            "2  Aartificial intelligence,API,Data science tech...  \n",
            "3  Aartificial intelligence,API,Data science tech...  \n",
            "4  Aartificial intelligence,Data science techniqu...  \n"
          ]
        }
      ],
      "source": [
        "def scrape_karkidi_jobs(keyword=\"data science\", pages=2):\n",
        "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "    base_url = \"https://www.karkidi.com/Find-Jobs/{page}/all/India?search={query}\"\n",
        "    jobs_list = []\n",
        "\n",
        "    for page in range(1, pages + 1):\n",
        "        url = base_url.format(page=page, query=keyword.replace(' ', '%20'))\n",
        "        print(f\"Scraping page: {page}\")\n",
        "        response = requests.get(url, headers=headers)\n",
        "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "        job_blocks = soup.find_all(\"div\", class_=\"ads-details\")\n",
        "        for job in job_blocks:\n",
        "            try:\n",
        "                title = job.find(\"h4\").get_text(strip=True)\n",
        "                company = job.find(\"a\", href=lambda x: x and \"Employer-Profile\" in x).get_text(strip=True)\n",
        "                location = job.find(\"p\").get_text(strip=True)\n",
        "                experience = job.find(\"p\", class_=\"emp-exp\").get_text(strip=True)\n",
        "                key_skills_tag = job.find(\"span\", string=\"Key Skills\")\n",
        "                Skills = key_skills_tag.find_next(\"p\").get_text(strip=True) if key_skills_tag else \"\"\n",
        "                summary_tag = job.find(\"span\", string=\"Summary\")\n",
        "                summary = summary_tag.find_next(\"p\").get_text(strip=True) if summary_tag else \"\"\n",
        "\n",
        "                jobs_list.append({\n",
        "                    \"Title\": title,\n",
        "                    \"Company\": company,\n",
        "                    \"Location\": location,\n",
        "                    \"Experience\": experience,\n",
        "                    \"Summary\": summary,\n",
        "                    \"Skills\": Skills\n",
        "                })\n",
        "            except Exception as e:\n",
        "                print(f\"Error parsing job block: {e}\")\n",
        "                continue\n",
        "\n",
        "        time.sleep(1)\n",
        "\n",
        "    return pd.DataFrame(jobs_list)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    df_jobs = scrape_karkidi_jobs(keyword=\"data science\", pages=2)\n",
        "    print(df_jobs.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_jobs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aF2F4krvCuBU",
        "outputId": "082bbc6a-0144-4481-9624-de34055d055f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_jobs.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTZDYPAqDDua",
        "outputId": "a019a8ba-daa3-4e2a-994e-d7f43e04bfa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Title', 'Company', 'Location', 'Experience', 'Summary', 'Skills'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_skills(df):\n",
        "    df[\"Skills\"] = df[\"Skills\"].apply(lambda x: x.lower())\n",
        "    df[\"Skills\"] = df[\"Skills\"].apply(lambda x: re.sub(r\"[^a-z, ]\", \"\", x))\n",
        "    df[\"Skills\"] = df[\"Skills\"].apply(lambda x: \", \".join(set(x.split(\", \"))))\n",
        "    return df\n",
        "\n",
        "def cluster_jobs(df, n_clusters=5):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    X = vectorizer.fit_transform(df[\"Skills\"])\n",
        "\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "    kmeans.fit(X)\n",
        "\n",
        "    df[\"cluster\"] = kmeans.labels_\n",
        "\n",
        "    # Save model and vectorizer\n",
        "    joblib.dump(kmeans, \"kmeans_model.pkl\")\n",
        "    joblib.dump(vectorizer, \"vectorizer.pkl\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# Full Pipeline Execution\n",
        "def main():\n",
        "    print(\"Scraping jobs from Karkidi.com...\")\n",
        "    df = scrape_karkidi_jobs()\n",
        "    print(f\"Scraped {len(df)} jobs.\")\n",
        "\n",
        "    print(\"Preprocessing skills...\")\n",
        "    df = preprocess_skills(df)\n",
        "\n",
        "    print(\"Clustering jobs...\")\n",
        "    df = cluster_jobs(df, n_clusters=5)\n",
        "\n",
        "    print(df.head())\n",
        "    df.to_csv(\"clustered_jobs.csv\", index=False)\n",
        "    print(\"Saved clustered job data to 'clustered_jobs.csv'\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zObSIvufC2tU",
        "outputId": "36f7b844-e216-4170-d27a-e19dbf1bfd8a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping jobs from Karkidi.com...\n",
            "Scraping page: 1\n",
            "Scraping page: 2\n",
            "Scraped 20 jobs.\n",
            "Preprocessing skills...\n",
            "Clustering jobs...\n",
            "                                               Title         Company  \\\n",
            "0          Machine Learning Physical Design Engineer          Google   \n",
            "1  Staff Software Engineer - Monetization, Poe (R...     Quora, Inc.   \n",
            "2  Staff Backend Engineer - Bot Creator Ecosystem...     Quora, Inc.   \n",
            "3  Senior Backend Engineer - Bot Creator Ecosyste...     Quora, Inc.   \n",
            "4                         Data Scientist Lead - AIML  JPMorgan Chase   \n",
            "\n",
            "                      Location Experience  \\\n",
            "0  Bengaluru, Karnataka, India   4-6 year   \n",
            "1                        India  8-10 year   \n",
            "2                        India  8-10 year   \n",
            "3                        India   6-8 year   \n",
            "4  Bengaluru, Karnataka, India   6-8 year   \n",
            "\n",
            "                                             Summary  \\\n",
            "0  Minimum qualifications:Bachelor's degree in El...   \n",
            "1  About Quora:Quora’s mission is to grow and sha...   \n",
            "2  About Quora:Quora’s mission is to grow and sha...   \n",
            "3  About Quora:Quora’s mission is to grow and sha...   \n",
            "4  We have an opportunity to impact your career a...   \n",
            "\n",
            "                                              Skills  cluster  \n",
            "0  aartificial intelligence,algorithms,data struc...        2  \n",
            "1  aartificial intelligence,analytical and proble...        1  \n",
            "2  aartificial intelligence,api,data science tech...        1  \n",
            "3  aartificial intelligence,api,data science tech...        1  \n",
            "4  aartificial intelligence,data science techniqu...        0  \n",
            "Saved clustered job data to 'clustered_jobs.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "awlTF5a2miVZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}